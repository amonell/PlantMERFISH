{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "be1a318e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import imageio as io\n",
    "import scanpy as sc\n",
    "import anndata as ad\n",
    "import os\n",
    "import logging\n",
    "from cellpose import models, io\n",
    "import glob\n",
    "from PIL import Image\n",
    "import cv2\n",
    "from tkinter import Tk     # from tkinter import Tk for Python 3.x\n",
    "from tkinter import filedialog\n",
    "from tkinter import *\n",
    "from tkinter import ttk\n",
    "from tkinter import simpledialog\n",
    "from tkinter import messagebox\n",
    "import tkinter as tk\n",
    "import os\n",
    "import logging\n",
    "from cellpose import models, io\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c60ba4e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3419345\n"
     ]
    }
   ],
   "source": [
    "def get_image(table):      \n",
    "    dict_detected = {}\n",
    "\n",
    "    xlist = d2['global_x'].astype(int).tolist()\n",
    "    ylist = d2['global_y'].astype(int).tolist()\n",
    "    print(len(xlist))\n",
    "    for i in range(len(xlist)):\n",
    "        dict_detected[xlist[i]] = []\n",
    "    for i in range(len(ylist)):\n",
    "        dict_detected[xlist[i]].append(ylist[i])\n",
    "\n",
    "    #create image from transcript locations\n",
    "    new_img = np.zeros((int(np.max(d2['global_x']+3000)), int(np.max(d2['global_y']+3000))))\n",
    "    for i in dict_detected.keys():\n",
    "        new_img[i][dict_detected.get(i)] = 1\n",
    "        \n",
    "    return dict_detected, new_img\n",
    "\n",
    "\n",
    "messagebox.showinfo(\"Option\",\"Please locate the region0 folder for the experiment\")\n",
    "root = Tk()\n",
    "root.withdraw()\n",
    "folder_selected1 = filedialog.askdirectory()\n",
    "\n",
    "messagebox.showinfo(\"Option\",\"Next question appearing shortly\")\n",
    "try:\n",
    "    detected_tanscripts = pd.read_csv(folder_selected1+os.path.sep+'detected_transcripts.csv')\n",
    "except:\n",
    "    print('detected_transcripts.csv not found in the folder')\n",
    "answer = simpledialog.askstring(\"Input\", \"Slices to run segmentation on (separated by commas)\")\n",
    "answer = answer.replace(' ', '')\n",
    "answer = answer.split(',')\n",
    "answer = [float(i) for i in answer]\n",
    "d2 = detected_tanscripts[detected_tanscripts['global_z'].isin(answer)]\n",
    "dict_detected, new_img = get_image(d2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b5f77fcc",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1 2 3 4 5 7 8 9 10 11 12 14 15 16 17 18 19 21 22 23 24 25 26 28 29 30 31 32 33 38 39 40 46 "
     ]
    }
   ],
   "source": [
    "\n",
    "messagebox.showinfo(\"Option\",\"Please select an output folder for the experiment analysis results\")\n",
    "folder_selected = filedialog.askdirectory()\n",
    "\n",
    "model = models.CellposeModel(gpu=True, pretrained_model='Models/CP_20220920_113001')\n",
    "# define CHANNELS to run segementation on\n",
    "# grayscale=0, R=1, G=2, B=3\n",
    "# channels = [cytoplasm, nucleus]\n",
    "# if NUCLEUS channel does not exist, set the second channel to 0\n",
    "channels = [0,0]\n",
    "masks = []\n",
    "flows = []\n",
    "styles = []\n",
    "diams = []\n",
    "ct = 0\n",
    "for i in range(2000, len(new_img[0]), 2000):\n",
    "    for j in range(2000, len(new_img[1]), 2000):      \n",
    "        ksize = (5, 5)\n",
    "\n",
    "        # Using cv2.blur() method \n",
    "        image = cv2.blur(new_img[i-2000:i, j-2000:j], ksize) \n",
    "        image = image * 255\n",
    "\n",
    "        try:\n",
    "            assert len(np.unique(image))>1\n",
    "            masks_, flows_, styles_= model.eval([image], channels=channels, diameter=22.92,flow_threshold=0.7, cellprob_threshold=-2)\n",
    "            masks.extend(masks_)\n",
    "            flows.extend(flows_)\n",
    "            styles.extend(styles_)\n",
    "            print(ct, end = ' ')\n",
    "        except (AssertionError):\n",
    "            try:\n",
    "                masks.append(np.zeros((len(image[0]), len(image[1]))))\n",
    "                flows.append([])\n",
    "                styles.append([])\n",
    "            except:\n",
    "                masks.append([])\n",
    "                flows.append([])\n",
    "                styles.append([])   \n",
    "        ct += 1\n",
    "temp_img_arr = []\n",
    "for i in range(2000, len(new_img[0]), 2000):\n",
    "    for j in range(2000, len(new_img[1]), 2000):      \n",
    "        ksize = (5, 5)\n",
    "\n",
    "        # Using cv2.blur() method \n",
    "        image = cv2.blur(new_img[i-2000:i, j-2000:j], ksize) \n",
    "        image = image * 255\n",
    "        temp_img_arr.append(image)\n",
    "io.save_masks(temp_img_arr, masks, flows, file_names=['stack_prestain_'+str(i).zfill(6)+'_cp_masks'+'.png' for i in range(len(temp_img_arr))], savedir = folder_selected + os.path.sep +'cellpose_predictions')\n",
    "try:\n",
    "    os.makedirs(folder_selected + os.path.sep +'images_for_cellpose_prediction')\n",
    "except:\n",
    "    None\n",
    "for i in range(len(temp_img_arr)):   \n",
    "    io.imsave(folder_selected + os.path.sep +'images_for_cellpose_prediction'+os.path.sep+'image-'+str(i)+'.tiff', temp_img_arr[i])\n",
    "\n",
    "from PIL import Image\n",
    "for i in range(len(masks)):\n",
    "    masks[i] = masks[i]+(i*10000)\n",
    "h_list = []\n",
    "for j in range(len(new_img[1])//2000):\n",
    "    h_list.append(np.hstack([masks[i] for i in range(j*(len(new_img[0])//2000),  j*(len(new_img[0])//2000)+ len(new_img[0])//2000)]))\n",
    "reconstruction = np.vstack(h_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "193ad42a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "masks_read = []\n",
    "for i in glob.glob(folder_selected + os.path.sep +'cellpose_predictions'+ os.path.sep+ '*.png'):\n",
    "    masks_read.append(np.array(Image.open(i)))\n",
    "\n",
    "h_list = []\n",
    "for j in range(len(new_img[1])//2000):\n",
    "    h_list.append(np.hstack([masks_read[i] for i in range(j*(len(new_img[0])//2000),  j*(len(new_img[0])//2000) + len(new_img[0])//2000)]))\n",
    "vizualized_reconstruction = np.vstack(h_list)\n",
    "io.imsave(folder_selected + os.path.sep +'cellmask_reconstruction.tiff', vizualized_reconstruction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "47440a68",
   "metadata": {},
   "outputs": [],
   "source": [
    "#vizualized_reconstruction = io.imread(folder_selected + os.path.sep +'cellmask_reconstruction.tiff')\n",
    "vizualized_reconstruction = np.clip(vizualized_reconstruction, 0, 1)\n",
    "adata = sc.read('DataPathogenPanel1/combined_filtered.h5')\n",
    "gene_to_id_table = pd.read_csv('DataPathogenPanel1/geneID_to_geneName_MERSCOPE_panel1.txt', sep='\\t', index_col=0)\n",
    "should_explore = messagebox.askyesno('Save all top 3 gene images?', 'Should the top 3 DE gene per cluster transcript images be saved? This may take a while')\n",
    "if should_explore == True:\n",
    "    try:\n",
    "        os.mkdir(folder_selected + os.path.sep + 'Transcript_ClusterTop3_Images')\n",
    "    except:\n",
    "        None\n",
    "    finding_cluster_markers = adata[:,adata.var.index.isin(set(gene_to_id_table['gene_name']))]\n",
    "    sc.tl.rank_genes_groups(finding_cluster_markers, groupby='seurat_clusters')\n",
    "    top3_DE = [i for i in finding_cluster_markers.uns['rank_genes_groups']['names']][:3]\n",
    "    top3_list = []\n",
    "    for i in range(len(top3_DE[0])):\n",
    "        top3_list.append([top3_DE[0][i], top3_DE[1][i], top3_DE[2][i]])\n",
    "\n",
    "    def display_gene_spatial(cell_image, gene_name, detected_transcript_df, cluster):\n",
    "        toplot = gene_to_id_table[gene_to_id_table['gene_name'] == gene_name]['gene_id']\n",
    "        xandy = detected_transcript_df[detected_transcript_df['gene'] == toplot.tolist()[0]]\n",
    "        x = xandy['global_x'].tolist()\n",
    "        y = xandy['global_y'].tolist()\n",
    "        plt.figure(figsize=(10, 10), dpi=100)\n",
    "        plt.ylim(len(cell_image.T),0)\n",
    "        plt.imshow(cell_image.T, vmax = 2.3, cmap = 'Greys_r')\n",
    "        plt.scatter(x, y, s = 0.15, color = 'cyan')\n",
    "        plt.title('Experiment '+ os.path.basename(folder_selected)+': Gene - '+gene_name+', Marker for Cluster '+str(cluster))\n",
    "        plt.savefig(folder_selected + os.path.sep + 'Transcript_ClusterTop3_Images'+os.path.sep + os.path.basename(folder_selected)+' - Gene - '+gene_name.split('.')[0].replace('/', '')+', Marker for Cluster '+str(cluster))\n",
    "        plt.close()\n",
    "\n",
    "    for i in range(len(top3_list)):\n",
    "        for j in range(len(top3_list[0])):\n",
    "            print(top3_list[i][j])\n",
    "            display_gene_spatial(vizualized_reconstruction, top3_list[i][j], detected_tanscripts, i)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43e25ad6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d25f2e21b144582940c186eb8b6dc62",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/550 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 "
     ]
    }
   ],
   "source": [
    "gene_list = np.unique(detected_tanscripts['gene'])\n",
    "cell_list = np.unique(reconstruction, return_counts=True)[0]\n",
    "cell_by_gene = pd.DataFrame(columns=gene_list, index=cell_list.astype(int))\n",
    "cell_by_gene = cell_by_gene.fillna(0)\n",
    "postions_not_in = []\n",
    "ct = 0\n",
    "for i in tqdm(gene_list):\n",
    "    hold_part = detected_tanscripts[detected_tanscripts['gene'] == i]\n",
    "    x_part = hold_part['global_x'].astype(int).tolist()\n",
    "    y_part = hold_part['global_y'].astype(int).tolist()   \n",
    "    for k in range(len(x_part)):\n",
    "        try:\n",
    "            value_at = reconstruction[x_part[k]][y_part[k]]\n",
    "            cell_by_gene.loc[value_at][i] += 1 \n",
    "        except:\n",
    "            postions_not_in.append((x_part,y_part, i))\n",
    "    ct += 1\n",
    "    print(ct, end = ' ')\n",
    "cell_by_gene.to_csv(folder_selected + os.path.sep + 'cell_by_gene.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e487278d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "adata = sc.read(folder_selected + os.path.sep + 'cell_by_gene.csv')\n",
    "adata.obs.index = cell_by_gene.index\n",
    "total_unique = []\n",
    "for i in range(len(masks)):\n",
    "#     print(np.unique(masks[i], return_counts=True)[0])\n",
    "    [total_unique.append(j) for j in np.unique(masks[i], return_counts=True)[1]]\n",
    "adata.obs['area'] = total_unique\n",
    "unique_cells_index = np.unique(reconstruction, return_index=True)[1]\n",
    "spatial = []\n",
    "for i in range(len(unique_cells_index)):\n",
    "    spatial.append([unique_cells_index[i] % len(reconstruction[0]), unique_cells_index[i] // len(reconstruction[0])])\n",
    "adata.obsm['X_spatial'] = np.array(spatial)\n",
    "adata = adata[adata.obs.index.astype(int) % 10000 != 0]\n",
    "num_transcripts = list(np.sum(adata.X, axis=1))\n",
    "adata.obs['transcripts_per_cell'] = num_transcripts\n",
    "total_gene = list(np.sum(adata.X, axis=0))\n",
    "adata.var['total_gene_counts'] = total_gene\n",
    "sc.pp.calculate_qc_metrics(adata, inplace=True)\n",
    "\n",
    "ax = sc.pl.violin(adata, 'n_genes_by_counts', jitter=0.4, multi_panel=False, show=False)\n",
    "ax.set_title('Counts per Gene, Average = '+str(np.round(np.mean(adata.obs['n_genes_by_counts']), 2)))\n",
    "ax.ylabel('Number of Transcripts')\n",
    "ax.xlabel('Gene')\n",
    "try: \n",
    "    os.mkdir('figures')\n",
    "except:\n",
    "    None\n",
    "plt.savefig('figures/violin_quality_metrics_cpg.png')\n",
    "plt.close()\n",
    "ax = sc.pl.violin(adata, 'total_counts', jitter=0.4, multi_panel=False, show=False)\n",
    "ax.set_title('Total Gene Counts Per Cell, Average = '+str(np.round(np.mean(adata.obs['total_counts']), 2)))\n",
    "ax.ylabel('Number of Transcripts')\n",
    "ax.xlabel('Cell')\n",
    "plt.savefig('figures/violin_quality_metrics_tgc.png')\n",
    "plt.close()\n",
    "\n",
    "#normalization\n",
    "for i in range(len(adata.X)):\n",
    "    #by area\n",
    "    #adata.X[i] /= total_unique[i]\n",
    "    #by tpc\n",
    "    adata.X[i] /= num_transcripts[i]\n",
    "adata = adata[adata.obs['transcripts_per_cell'] >= 50]\n",
    "sc.pp.log1p(adata)\n",
    "sc.tl.pca(adata)\n",
    "sc.pp.neighbors(adata)\n",
    "sc.tl.leiden(adata)\n",
    "sc.tl.umap(adata)\n",
    "\n",
    "sc.pl.umap(adata, color='leiden', vmax=0.05, save = '_leiden.png', show = False)\n",
    "sc.pl.embedding(adata, basis='spatial', color='leiden', vmax=0.05, size=10, save = '_leiden.png', show = False)\n",
    "adata.write(folder_selected + os.path.sep + 'adata.h5ad')\n",
    "source = r'figures'\n",
    "destination = folder_selected\n",
    "allfiles = ['umap_leiden.png', 'spatial_leiden.png', 'violin_quality_metrics_cpg.png', 'violin_quality_metrics_tgc.png']\n",
    "for f in allfiles:\n",
    "    src_path = os.path.join(source, f)\n",
    "    dst_path = os.path.join(destination, f)\n",
    "    shutil.move(src_path, dst_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cb4c351",
   "metadata": {},
   "source": [
    "# For training on the 2 slice set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9eee438",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "#create cellpose images for labeling\n",
    "for i in range(2000, len(new_img[0]), 2000):\n",
    "    for j in range(2000, len(new_img[1]), 2000):      \n",
    "        plt.imshow(new_img[i-2000:i, j-2000:j], vmax=1, cmap='gray')\n",
    "        plt.show()\n",
    "        value = input(\"y or n\")\n",
    "        if value == 'y':\n",
    "            io.imsave(r'C:\\Users\\amonell\\Downloads\\label_cellpose_images_allslice\\labeling'+str(i)+'_to_'+str(j)+'.tiff', new_img[i-2000:i, j-2000:j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ab46514",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "#used to create images for cellpose training\n",
    "for i in range(2000, len(new_img[0]), 2000):\n",
    "    for j in range(2000, len(new_img[1]), 2000):      \n",
    "        plt.imshow(new_img[i-2000:i, j-2000:j], vmax=1, cmap='gray')\n",
    "        plt.show()\n",
    "        value = input(\"y or n\")\n",
    "        if value == 'y':\n",
    "            # ksize\n",
    "            ksize = (5, 5)\n",
    "\n",
    "            # Using cv2.blur() method \n",
    "            image = cv2.blur(new_img[i-2000:i, j-2000:j], ksize) \n",
    "            image = image * 255\n",
    "            io.imsave(r'C:\\Users\\amonell\\Downloads\\transcript_images_to_label_slice3\\training'+str(i)+'_to_'+str(j)+'.tiff', image)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "237dd078",
   "metadata": {},
   "source": [
    "# For training on all slices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "57872789",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "#create cellpose images for labeling\n",
    "for i in range(2000, len(new_img_all[0]), 2000):\n",
    "    for j in range(2000, len(new_img_all[1]), 2000):      \n",
    "        plt.imshow(new_img_all[i-2000:i, j-2000:j], vmax=1, cmap='gray')\n",
    "        plt.show()\n",
    "        value = input(\"y or n\")\n",
    "        if value == 'y':\n",
    "            io.imsave(r'C:\\Users\\amonell\\Downloads\\label_cellpose_images_allslice\\labeling'+str(i)+'_to_'+str(j)+'.tiff', new_img[i-2000:i, j-2000:j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a8d6e657",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "#used to create images for cellpose training\n",
    "for i in range(2000, len(new_img_all[0]), 2000):\n",
    "    for j in range(2000, len(new_img_all[1]), 2000):      \n",
    "        plt.imshow(new_img_all[i-2000:i, j-2000:j], vmax=1, cmap='gray')\n",
    "        plt.show()\n",
    "        value = input(\"y or n\")\n",
    "        if value == 'y':\n",
    "            # ksize\n",
    "            ksize = (5, 5)\n",
    "\n",
    "            # Using cv2.blur() method \n",
    "            image = cv2.blur(new_img_all[i-2000:i, j-2000:j], ksize) \n",
    "            image = image * 255\n",
    "            io.imsave(r'C:\\Users\\amonell\\Downloads\\label_cellpose_images_allslice\\training'+str(i)+'_to_'+str(j)+'.tiff', image)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
